% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}

\addto\captionsenglish{\renewcommand{\figurename}{Fig. }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\floatname{literal-block}{Listing }



\title{DRM Documentation}
\date{April 02, 2017}
\release{0.1}
\author{Michele D'Asaro, Umut Guclu, Marcel van Gerven}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{Introduction}
\label{intro:introduction}\label{intro::doc}\label{intro:drm-documentation}
The Dynamic Representational Modeling (DRM) framework is used for end-to-end training of neural systems. The goal is to model
human brains by constructing artificial brains that are `as close as possible'. The
way to realize this is by being explicit about how neuronal populations interact with
sensory input, with each other and with motor output. Furthermore, we need to make
explicit how \emph{measurements} of neural activity are related to neuronal population activity.

There are two ways in which we can link physical to artificial brains:
1) Construct artificial brain and condition it on neural observations. The assumption is that population
responses emerge in the artificial brain that are indicative of neural processing in the physical brain.
2) Construct artificial brain and have it perform the same cognitive task as the physical brain.
Then compare population responses.

For now we focus on the first approach.


\section{General approach}
\label{intro:general-approach}
DRM assumes that all components in an artifical brain are neural networks.
That is, we have populations, connections, and readout mechanisms that are all specified
in terms of neural networks. These networks can implement very specific mechanisms such
as conduction delays, neural response functions, etc.

Our goal at each modeling state is to be as explicit as possible about the underlying
neural processes. That is, how does our artificial brain relate to neuronal time constants,
connectivity structure, etc.


\section{Usage}
\label{intro:usage}
The goal of DRM is to provide a modeling framework where the artificial brains are trained end-to-end to provide the
most explicit model of neural information processing possible for a task at hand.

Using DRM we can:
1) make explicit what kind of information is being processed by certain neuronal populations
2) compare different models (e.g. assumptions on connectivity structure, etc) through model comparison.


\section{Artificial brains}
\label{intro:artificial-brains}
An artificial brain (DRMNet) is a neural network consisting of sensory inputs and neuronal populations.
Neuronal populations are connected to motor outputs and/or readouts (measurements). Populations, readouts
and connections are all inherited from DRMNode.

The artificial brain is trained end-to-end, either on behavioural output or neural output. Training is
facilitated by a DRM object which just wraps the standard neural network training procedure. Below we list components of a DRMNet.


\section{Stimulus}
\label{intro:stimulus}
A stimulus is a sensory input which can be connected to a subset of the neuronal populations. We can
have multiple sensory inputs that are each connected to different subsets.


\section{Populations}
\label{intro:populations}
A DRMNet consists of a set of neuronal populations (DRMPopulation). Populations can have
physical locations, measurement units, etc. Populations are linked to sensory input, each other
and to the readouts via connections (DRMConnection).


\section{Connections}
\label{intro:connections}
Stimuli, neuronal populations and readouts are connected to each other
via connections. These connections implement conduction delays, HRFs, etc.
Below we list a default connection.


\subsection{Tapped delay line}
\label{intro:tapped-delay-line}
Stimuli are connected to populations and populations are connected to each other. A basic way
to realize such connections is using \emph{tapped delay lines}. These connections implement the
notion that physical information transmission (via axons) takes time. Given a sampling resolution
of \emph{r} ms, a tapped delay line can delay the sample by \emph{n} samples to instantiate conduction delay.

Note that this delay is necessary in order to make the artificial brain acyclic. I.e., if
we run backpropagation then a delay of at least one sample ensures that we can unroll the
neural network over time. A tapped delay line without any delay is an identity mapping.

Note further that this way of implementing an RNN gives a model in which updating is
asynchronous in the sense that the same information may be processed by different populations
at different points in time, like in biological neural networks.


\section{Readout}
\label{intro:readout}
A readout receives the output of all neuronal populations. It is itself responsible for
how to handle these outputs. A readout can be either behavioural (motor)
output or a neural measurement. The readout mechanism itself integrates population responses
and translates this into something which can be passed onto a loss function.
An important objective is to separate readout properties from neural information processing.
We can have multiple readouts that yield (a sum of) multiple loss functions. We list some examples below.


\subsection{BOLD readout}
\label{intro:bold-readout}
A BOLD readout could be implemented by linking each population to that subset of voxels that
represent that population (e.g. V1). Suppose we have two populations (say V1 and V2). Then
the readout will use the V1 population response to predict V1 voxels (or their average signal)
and V2 population response to predict V2 voxels (or their average signal). The hemodynamic delay
can be implemented by internally using parameterized functions (e.g. double gammas)
or memory units to learn e.g. the HRF more flexibly.


\subsection{M/EEG readout}
\label{intro:m-eeg-readout}
In this case, we listen to all populations and use a lead field matrix to represent sensor
output as a linear combination of the population responses


\subsection{Single population recordings}
\label{intro:single-population-recordings}
In this case the readout mechanism ignores all populations except the one we record from.


\subsection{Motor outputs}
\label{intro:motor-outputs}
Motor outputs (button presses, eye movements) can be modelled using separate readouts that
reflect behavioural ouput.


\section{Confounds}
\label{intro:confounds}
Confounds such as breathing, heart beat, etc. can affect the readouts. We model these as
direct additional inputs to the readout mechanism.


\section{Connectivity}
\label{intro:connectivity}
Connectivity between stimuli and populations and among populations are handled via a
sparse vector and sparse matrix. None elements indicate absence of a connection. The other
elements contain DRMConnection objects.


\section{Data}
\label{intro:data}
Data is handled via a DRMIterator object. This object is responsible for producing sensory input,
measurements and confounds at the sampling rate \emph{r}. Note that each at time step, we may
\begin{quote}

have missing data. That is, the stimulus
\end{quote}
\begin{description}
\item[{may be absent, confounds may not be measured, and responses may not be measured}] \leavevmode
(e.g. slow sampling of the hemodynamic response). On the input side, we use zeros to indicate
absence of input (this may not always be valid). On the output side, this is handled by just
ignoring outputs when computing the loss.

\end{description}


\section{Training}
\label{intro:training}
Training takes place using truncated backpropagation on the (partially observed) data


\chapter{DRM package}
\label{DRM:drm-package}\label{DRM::doc}\label{DRM:module-DRM.base}\index{DRM.base (module)}\index{DRM (class in DRM.base)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRM}\pysiglinewithargsret{\strong{class }\code{DRM.base.}\bfcode{DRM}}{\emph{drm\_net}}{}
Bases: \code{object}

wrapper object that trains and analyses the model at hand
\index{estimate() (DRM.base.DRM method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRM.estimate}\pysiglinewithargsret{\bfcode{estimate}}{\emph{data\_iter}, \emph{val\_iter=None}, \emph{n\_epochs=1}, \emph{cutoff=None}}{}
Estimation via truncated backprop
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{data\_iter}} -- iterator which generates sensations/responses at some specified resolution

\item {} 
\textbf{\texttt{val\_iter}} -- optional iterator which generates sensations/responses at some specified resolution used for validation

\item {} 
\textbf{\texttt{n\_epochs}} -- number of training epochs

\item {} 
\textbf{\texttt{cutoff}} -- cutoff for truncated backpropagation

\end{itemize}

\item[{Returns}] \leavevmode
train loss and validation loss

\end{description}\end{quote}

\end{fulllineitems}

\index{forward() (DRM.base.DRM method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRM.forward}\pysiglinewithargsret{\bfcode{forward}}{\emph{data\_iter}}{}
Forward propagation
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{data\_iter}} -- 

\item[{Returns}] \leavevmode
generated response and population activity

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{DRMLoss (class in DRM.base)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMLoss}\pysigline{\strong{class }\code{DRM.base.}\bfcode{DRMLoss}}
Bases: \code{torch.nn.modules.module.Module}

MSE loss which ignores missing data
\index{forward() (DRM.base.DRMLoss method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMLoss.forward}\pysiglinewithargsret{\bfcode{forward}}{\emph{prediction}, \emph{target}}{}
Computes loss on a prediction and a target

Computes MSE loss but ignores those terms where the target is equal to nan, indicating missing data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{prediction}} (\emph{Variable}) -- Prediction of output

\item {} 
\textbf{\texttt{target}} (\emph{Variable}) -- Target output

\end{itemize}

\item[{Returns}] \leavevmode
MSE loss

\item[{Return type}] \leavevmode
Variable

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{DRMNet (class in DRM.base)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNet}\pysiglinewithargsret{\strong{class }\code{DRM.base.}\bfcode{DRMNet}}{\emph{populations}, \emph{ws}, \emph{Wp}, \emph{readout}}{}
Bases: \code{torch.nn.modules.container.Sequential}
\index{detach\_() (DRM.base.DRMNet method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNet.detach_}\pysiglinewithargsret{\bfcode{detach\_}}{}{}
Detach gradients for truncation

\end{fulllineitems}

\index{forward() (DRM.base.DRMNet method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNet.forward}\pysiglinewithargsret{\bfcode{forward}}{\emph{x}}{}
Forward propagation
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{x}} -- sensory input at this point in time (zeros for no input); numpy array

\item[{Returns}] \leavevmode
predicted output measurements

\end{description}\end{quote}

\end{fulllineitems}

\index{reset() (DRM.base.DRMNet method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNet.reset}\pysiglinewithargsret{\bfcode{reset}}{}{}
Reset states of model components

\end{fulllineitems}


\end{fulllineitems}

\index{DRMNode (class in DRM.base)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNode}\pysiglinewithargsret{\strong{class }\code{DRM.base.}\bfcode{DRMNode}}{\emph{n\_in=1}, \emph{n\_out=1}}{}
Bases: \code{torch.nn.modules.module.Module}

Base class for populations, readouts and connections
\index{detach\_() (DRM.base.DRMNode method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNode.detach_}\pysiglinewithargsret{\bfcode{detach\_}}{}{}
Detach gradients for truncation

\end{fulllineitems}

\index{forward() (DRM.base.DRMNode method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNode.forward}\pysiglinewithargsret{\bfcode{forward}}{\emph{x}}{}
Forward pass for this node
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{x}} -- input data

\item[{Returns}] \leavevmode
output data

\end{description}\end{quote}

\end{fulllineitems}

\index{reset() (DRM.base.DRMNode method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.base.DRMNode.reset}\pysiglinewithargsret{\bfcode{reset}}{}{}
The function that is called when resetting internal state

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{DRM:module-DRM.connection}\index{DRM.connection (module)}\index{DRMConnection (class in DRM.connection)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.connection.DRMConnection}\pysiglinewithargsret{\strong{class }\code{DRM.connection.}\bfcode{DRMConnection}}{\emph{n\_in=1}, \emph{n\_out=1}, \emph{delay=1}}{}
Bases: {\hyperref[DRM:DRM.base.DRMNode]{\emph{\code{DRM.base.DRMNode}}}}
\index{detach\_() (DRM.connection.DRMConnection method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.connection.DRMConnection.detach_}\pysiglinewithargsret{\bfcode{detach\_}}{}{}
Detach gradients for truncation

\end{fulllineitems}

\index{forward() (DRM.connection.DRMConnection method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.connection.DRMConnection.forward}\pysiglinewithargsret{\bfcode{forward}}{\emph{x}}{}
Forward propagation
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{x}} -- input to connection

\item[{Returns}] \leavevmode
connection output

\end{description}\end{quote}

\end{fulllineitems}

\index{reset() (DRM.connection.DRMConnection method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.connection.DRMConnection.reset}\pysiglinewithargsret{\bfcode{reset}}{}{}
Reset state

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{DRM:module-DRM.iterators}\index{DRM.iterators (module)}\index{DRMIterator (class in DRM.iterators)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.iterators.DRMIterator}\pysiglinewithargsret{\strong{class }\code{DRM.iterators.}\bfcode{DRMIterator}}{\emph{resolution}, \emph{stimulus}, \emph{stim\_time}, \emph{response=None}, \emph{resp\_time=None}, \emph{batch\_size=None}, \emph{n\_batches=None}}{}
Bases: \code{object}
\index{\_\_iter\_\_() (DRM.iterators.DRMIterator method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.iterators.DRMIterator.__iter__}\pysiglinewithargsret{\bfcode{\_\_iter\_\_}}{}{}
Initializes data generator. Should be invoked at the start of each epoch
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
self

\end{description}\end{quote}

\end{fulllineitems}

\index{is\_final() (DRM.iterators.DRMIterator method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.iterators.DRMIterator.is_final}\pysiglinewithargsret{\bfcode{is\_final}}{}{}
Flags if final iteration is reached
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
boolean if final batch is reached

\end{description}\end{quote}

\end{fulllineitems}

\index{next() (DRM.iterators.DRMIterator method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.iterators.DRMIterator.next}\pysiglinewithargsret{\bfcode{next}}{}{}
Produces next data item
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
dictionary containing the stimulus and the response as torch variables

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{DRM:module-DRM.population}\index{DRM.population (module)}\index{DRMPopulation (class in DRM.population)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.population.DRMPopulation}\pysiglinewithargsret{\strong{class }\code{DRM.population.}\bfcode{DRMPopulation}}{\emph{n\_in=1}, \emph{n\_out=1}, \emph{delay=1}}{}
Bases: {\hyperref[DRM:DRM.base.DRMNode]{\emph{\code{DRM.base.DRMNode}}}}
\index{forward() (DRM.population.DRMPopulation method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.population.DRMPopulation.forward}\pysiglinewithargsret{\bfcode{forward}}{\emph{x}}{}
Forward propagation
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{x}} (\emph{list of afferent population outputs}) -- population input

\item[{Returns}] \leavevmode
population output

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{DRM:module-DRM.readout}\index{DRM.readout (module)}\index{DRMReadout (class in DRM.readout)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.readout.DRMReadout}\pysiglinewithargsret{\strong{class }\code{DRM.readout.}\bfcode{DRMReadout}}{\emph{n\_in=1}, \emph{n\_out=1}}{}
Bases: {\hyperref[DRM:DRM.base.DRMNode]{\emph{\code{DRM.base.DRMNode}}}}
\index{forward() (DRM.readout.DRMReadout method)}

\begin{fulllineitems}
\phantomsection\label{DRM:DRM.readout.DRMReadout.forward}\pysiglinewithargsret{\bfcode{forward}}{\emph{x}}{}
Forward propagation
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{x}} (\emph{list of afferent population outputs}) -- readout input

\item[{Returns}] \leavevmode
predicted measurements

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\DUspan{xref,std,std-ref}{genindex}

\item {} 
\DUspan{xref,std,std-ref}{modindex}

\item {} 
\DUspan{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{d}
\item {\texttt{DRM.base}}, \pageref{DRM:module-DRM.base}
\item {\texttt{DRM.connection}}, \pageref{DRM:module-DRM.connection}
\item {\texttt{DRM.iterators}}, \pageref{DRM:module-DRM.iterators}
\item {\texttt{DRM.population}}, \pageref{DRM:module-DRM.population}
\item {\texttt{DRM.readout}}, \pageref{DRM:module-DRM.readout}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
